{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import configparser\n",
    "from datetime import datetime\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import IntegerType, TimestampType\n",
    "from pyspark.sql.functions import udf, col, desc, row_number\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, date_format, col, monotonically_increasing_id\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dl.cfg']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('dl.cfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_spark_session():\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    "        .getOrCreate()\n",
    "    return spark\n",
    "\n",
    "spark = create_spark_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "input_data = \"data/\"\n",
    "output_data = \"data/output_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# get filepath to song data file\n",
    "song_data = input_data + \"song-data/song-data/*/*/*/*.json\" \n",
    "\n",
    "# read song data file\n",
    "df = spark.read.json(song_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- artist_latitude: double (nullable = true)\n",
      " |-- artist_location: string (nullable = true)\n",
      " |-- artist_longitude: double (nullable = true)\n",
      " |-- artist_name: string (nullable = true)\n",
      " |-- duration: double (nullable = true)\n",
      " |-- num_songs: long (nullable = true)\n",
      " |-- song_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------------+-----------------+----------------+--------------------+---------+---------+------------------+--------------------+----+\n",
      "|         artist_id|artist_latitude|  artist_location|artist_longitude|         artist_name| duration|num_songs|           song_id|               title|year|\n",
      "+------------------+---------------+-----------------+----------------+--------------------+---------+---------+------------------+--------------------+----+\n",
      "|ARDR4AC1187FB371A1|           null|                 |            null|Montserrat Caball...|511.16363|        1|SOBAYLL12A8C138AF9|Sono andati? Fing...|   0|\n",
      "|AREBBGV1187FB523D2|           null|      Houston, TX|            null|Mike Jones (Featu...|173.66159|        1|SOOLYAZ12A6701F4A6|Laws Patrolling (...|   0|\n",
      "|ARMAC4T1187FB3FA4C|       40.82624|Morris Plains, NJ|       -74.47995|The Dillinger Esc...|207.77751|        1|SOBBUGU12A8C13E95D|Setting Fire to S...|2004|\n",
      "|ARPBNLO1187FB3D52F|       40.71455|     New York, NY|       -74.00712|            Tiny Tim| 43.36281|        1|SOAOIBZ12AB01815BE|I Hold Your Hand ...|2000|\n",
      "|ARDNS031187B9924F0|       32.67828|          Georgia|       -83.22295|          Tim Wilson|186.48771|        1|SONYPOM12A8C13B2D7|I Think My Wife I...|2005|\n",
      "+------------------+---------------+-----------------+----------------+--------------------+---------+---------+------------------+--------------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "songs_table = df.select(\"song_id\", \"title\", \"artist_id\", \"year\", \"duration\").dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------------+-----------------+----------------+--------------------+---------+---------+------------------+--------------------+----+\n",
      "|         artist_id|artist_latitude|  artist_location|artist_longitude|         artist_name| duration|num_songs|           song_id|               title|year|\n",
      "+------------------+---------------+-----------------+----------------+--------------------+---------+---------+------------------+--------------------+----+\n",
      "|ARDR4AC1187FB371A1|           null|                 |            null|Montserrat Caball...|511.16363|        1|SOBAYLL12A8C138AF9|Sono andati? Fing...|   0|\n",
      "|AREBBGV1187FB523D2|           null|      Houston, TX|            null|Mike Jones (Featu...|173.66159|        1|SOOLYAZ12A6701F4A6|Laws Patrolling (...|   0|\n",
      "|ARMAC4T1187FB3FA4C|       40.82624|Morris Plains, NJ|       -74.47995|The Dillinger Esc...|207.77751|        1|SOBBUGU12A8C13E95D|Setting Fire to S...|2004|\n",
      "|ARPBNLO1187FB3D52F|       40.71455|     New York, NY|       -74.00712|            Tiny Tim| 43.36281|        1|SOAOIBZ12AB01815BE|I Hold Your Hand ...|2000|\n",
      "|ARDNS031187B9924F0|       32.67828|          Georgia|       -83.22295|          Tim Wilson|186.48771|        1|SONYPOM12A8C13B2D7|I Think My Wife I...|2005|\n",
      "+------------------+---------------+-----------------+----------------+--------------------+---------+---------+------------------+--------------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "songs_table.write.option(\"header\",True) \\\n",
    "    .partitionBy(\"year\",\"artist_id\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .parquet(output_data + \"songs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# artists_table = df.select(\"artist_id\", col(\"name\") as \"artist_name\", col(\"location\") as \"artist_location\", col(\"lattitude\") as \"artist_lattitude\", col(\"longitude\") as \"artist_longitude\").dropDuplicates()\n",
    "artists_table = df.select(\"artist_id\", df[\"artist_name\"].alias(\"name\"), \\\n",
    "                          df[\"artist_location\"].alias(\"location\"), \\\n",
    "                          df[\"artist_latitude\"].alias(\"latitude\"), \\\n",
    "                          df[\"artist_longitude\"].alias(\"longitude\")).dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "artists_table.write.option(\"header\",True) \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .parquet(output_data + \"artists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+--------------------+--------+---------+\n",
      "|         artist_id|                name|            location|latitude|longitude|\n",
      "+------------------+--------------------+--------------------+--------+---------+\n",
      "|ARDR4AC1187FB371A1|Montserrat Caball...|                    |    null|     null|\n",
      "|ARMAC4T1187FB3FA4C|The Dillinger Esc...|   Morris Plains, NJ|40.82624|-74.47995|\n",
      "|ARNF6401187FB57032|   Sophie B. Hawkins|New York, NY [Man...|40.79086|-73.96644|\n",
      "|AROUOZZ1187B9ABE51|         Willie Bobo|New York, NY [Spa...|40.79195|-73.94512|\n",
      "|ARI2JSK1187FB496EF|Nick Ingman;Gavyn...|     London, England|51.50632| -0.12714|\n",
      "+------------------+--------------------+--------------------+--------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parDF1=spark.read.parquet(output_data + \"artists\")\n",
    "parDF1.limit(5).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# get filepath to song data file\n",
    "song_data = input_data + \"song-data/song-data/*.json\"\n",
    "\n",
    "# read song data file\n",
    "df = spark.read.json(song_data)\n",
    "\n",
    "# extract columns to create songs table\n",
    "songs_table = df.select(\"song_id\", \"title\", \"artist_id\", \"year\", \"duration\").dropDuplicates()\n",
    "\n",
    "# write songs table to parquet files partitioned by year and artist\n",
    "songs_table.write.option(\"header\",True) \\\n",
    "    .partitionBy(\"year\",\"artist_id\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .parquet(output_data + \"songs\")\n",
    "\n",
    "# extract columns to create artists table\n",
    "artists_table = df.select(\"artist_id\", df[\"artist_name\"].alias(\"name\"), \\\n",
    "                          df[\"artist_location\"].alias(\"location\"), \\\n",
    "                          df[\"artist_latitude\"].alias(\"latitude\"), \\\n",
    "                          df[\"artist_longitude\"].alias(\"longitude\")).dropDuplicates()\n",
    "\n",
    "# write artists table to parquet files\n",
    "artists_table.write.option(\"header\",True) \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .parquet(output_data + \"artists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+---------+------+-------------+--------+---------+-----+--------------------+------+--------+-----------------+---------+--------------------+------+-------------+--------------------+------+\n",
      "|     artist|     auth|firstName|gender|itemInSession|lastName|   length|level|            location|method|    page|     registration|sessionId|                song|status|           ts|           userAgent|userId|\n",
      "+-----------+---------+---------+------+-------------+--------+---------+-----+--------------------+------+--------+-----------------+---------+--------------------+------+-------------+--------------------+------+\n",
      "|   Harmonia|Logged In|     Ryan|     M|            0|   Smith|655.77751| free|San Jose-Sunnyval...|   PUT|NextSong|1.541016707796E12|      583|       Sehr kosmisch|   200|1542241826796|\"Mozilla/5.0 (X11...|    26|\n",
      "|The Prodigy|Logged In|     Ryan|     M|            1|   Smith|260.07465| free|San Jose-Sunnyval...|   PUT|NextSong|1.541016707796E12|      583|     The Big Gundown|   200|1542242481796|\"Mozilla/5.0 (X11...|    26|\n",
      "|      Train|Logged In|     Ryan|     M|            2|   Smith|205.45261| free|San Jose-Sunnyval...|   PUT|NextSong|1.541016707796E12|      583|            Marry Me|   200|1542242741796|\"Mozilla/5.0 (X11...|    26|\n",
      "|Sony Wonder|Logged In|   Samuel|     M|            0|Gonzalez|218.06975| free|Houston-The Woodl...|   PUT|NextSong|1.540492941796E12|      597|           Blackbird|   200|1542253449796|\"Mozilla/5.0 (Mac...|    61|\n",
      "|  Van Halen|Logged In|    Tegan|     F|            2|  Levine|289.38404| paid|Portland-South Po...|   PUT|NextSong|1.540794356796E12|      602|Best Of Both Worl...|   200|1542260935796|\"Mozilla/5.0 (Mac...|    80|\n",
      "+-----------+---------+---------+------+-------------+--------+---------+-----+--------------------+------+--------+-----------------+---------+--------------------+------+-------------+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get filepath to log data file\n",
    "log_data = input_data + \"log-data/*.json\"\n",
    "song_data = input_data + \"song-data/song-data/*/*/*/*.json\" \n",
    "# read log data file\n",
    "df = spark.read.json(log_data)\n",
    "\n",
    "# filter by actions for song plays\n",
    "df = df.filter(df.page == 'NextSong')\n",
    "\n",
    "df.limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist: string (nullable = true)\n",
      " |-- auth: string (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- itemInSession: long (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- method: string (nullable = true)\n",
      " |-- page: string (nullable = true)\n",
      " |-- registration: double (nullable = true)\n",
      " |-- sessionId: long (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- status: long (nullable = true)\n",
      " |-- ts: long (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# users_table = df.select(col(\"userId\") as \"user_id\", col(\"firstName\") as \"first_name\",\\\n",
    "#                         col(\"last_Name\") as \"last_name\", \"gender\", \"level\").dropDuplicates()\n",
    "\n",
    "users_table = df.select(df[\"userId\"].alias(\"user_id\"), \\\n",
    "                        df[\"firstName\"].alias(\"first_name\"), \\\n",
    "                        df[\"lastName\"].alias(\"last_name\"), \\\n",
    "                        \"gender\", \"level\", \"ts\").dropDuplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+---------+------+-----+-------------+\n",
      "|user_id|first_name|last_name|gender|level|           ts|\n",
      "+-------+----------+---------+------+-----+-------------+\n",
      "|     97|      Kate|  Harrell|     F| paid|1542308354796|\n",
      "|     80|     Tegan|   Levine|     F| paid|1542174581796|\n",
      "|     80|     Tegan|   Levine|     F| paid|1542179185796|\n",
      "|     16|     Rylan|   George|     M| paid|1542185237796|\n",
      "|     80|     Tegan|   Levine|     F| paid|1542215370796|\n",
      "+-------+----------+---------+------+-----+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users_table.limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+---------+------+-----+\n",
      "|user_id|first_name|last_name|gender|level|\n",
      "+-------+----------+---------+------+-----+\n",
      "|     51|      Maia|    Burke|     F| free|\n",
      "|      7|    Adelyn|   Jordan|     F| free|\n",
      "|     15|      Lily|     Koch|     F| paid|\n",
      "|     54|     Kaleb|     Cook|     M| free|\n",
      "|    101|    Jayden|      Fox|     M| free|\n",
      "|     11| Christian|   Porter|     F| free|\n",
      "|     29|Jacqueline|    Lynch|     F| paid|\n",
      "|     69|  Anabelle|  Simpson|     F| free|\n",
      "|     42|    Harper|  Barrett|     M| paid|\n",
      "|     73|     Jacob|    Klein|     M| paid|\n",
      "|     87|    Dustin|      Lee|     M| free|\n",
      "|     64|    Hannah|  Calhoun|     F| free|\n",
      "|      3|     Isaac|   Valdez|     M| free|\n",
      "|     30|     Avery|  Watkins|     F| paid|\n",
      "|     34|    Evelin|    Ayala|     F| free|\n",
      "|     59|      Lily|   Cooper|     F| free|\n",
      "|      8|    Kaylee|  Summers|     F| free|\n",
      "|     22|      Sean|   Wilson|     F| free|\n",
      "|     28|  Brantley|     West|     M| free|\n",
      "|     85|   Kinsley|    Young|     F| paid|\n",
      "+-------+----------+---------+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# val windowSpec = Window.partitionBy(\"user_id\").orderBy(desc(\"ts\"))                                                           \n",
    "# users_table = users_table.withColumn(\"row_number\", row_number.over(windowSpec))\n",
    "# users_table = users_table.filter(users_table.row_number == 1).drop(\"row_number\")\n",
    "\n",
    "user_window = Window \\\n",
    "    .partitionBy('user_id') \\\n",
    "    .orderBy(desc('ts')) \\\n",
    "\n",
    "users_table = users_table.withColumn(\"row_number\", row_number().over(user_window))\n",
    "\n",
    "users_table = users_table.filter(users_table.row_number == 1).drop(\"row_number\").drop(\"ts\")\n",
    "\n",
    "users_table.limit(100).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist: string (nullable = true)\n",
      " |-- auth: string (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- itemInSession: long (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- method: string (nullable = true)\n",
      " |-- page: string (nullable = true)\n",
      " |-- registration: double (nullable = true)\n",
      " |-- sessionId: long (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- status: long (nullable = true)\n",
      " |-- ts: long (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- start_time: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "users_table.write.option(\"header\",True) \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .parquet(output_data + \"users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create timestamp column from original timestamp column\n",
    "get_timestamp = udf(lambda ts : int(int(ts)/1000),  IntegerType())\n",
    "df = df.withColumn(\"timestamp\", get_timestamp(\"ts\"))\n",
    "\n",
    "# create datetime column from original timestamp column\n",
    "get_datetime = udf(lambda ts : datetime.fromtimestamp(ts), TimestampType())\n",
    "df = df.withColumn(\"start_time\", get_datetime(\"timestamp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-------------------+\n",
      "|           ts| timestamp|         start_time|\n",
      "+-------------+----------+-------------------+\n",
      "|1542241826796|1542241826|2018-11-15 00:30:26|\n",
      "|1542242481796|1542242481|2018-11-15 00:41:21|\n",
      "|1542242741796|1542242741|2018-11-15 00:45:41|\n",
      "|1542253449796|1542253449|2018-11-15 03:44:09|\n",
      "|1542260935796|1542260935|2018-11-15 05:48:55|\n",
      "+-------------+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"ts\", \"timestamp\", \"start_time\").limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "time_table = df.select(\"start_time\", hour(\"start_time\").alias(\"hour\"), dayofmonth(\"start_time\").alias(\"day\"), \\\n",
    "                       weekofyear(\"start_time\").alias(\"week\"), month(\"start_time\").alias(\"month\"), \\\n",
    "                       year(\"start_time\").alias(\"year\")).withColumn(\"weekday\", date_format(col(\"start_time\"), \"u\")).dropDuplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+---+----+-----+----+-------+\n",
      "|         start_time|hour|day|week|month|year|weekday|\n",
      "+-------------------+----+---+----+-----+----+-------+\n",
      "|2018-11-15 07:08:36|   7| 15|  46|   11|2018|      4|\n",
      "|2018-11-15 11:32:33|  11| 15|  46|   11|2018|      4|\n",
      "|2018-11-21 05:50:57|   5| 21|  47|   11|2018|      3|\n",
      "|2018-11-14 08:54:49|   8| 14|  46|   11|2018|      3|\n",
      "|2018-11-14 16:34:43|  16| 14|  46|   11|2018|      3|\n",
      "+-------------------+----+---+----+-----+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time_table.limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "time_table.write.option(\"header\",True) \\\n",
    "    .partitionBy(\"year\",\"month\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .parquet(output_data + \"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "song_df = spark.read.json(song_data)\n",
    "\n",
    "# extract columns from joined song and log datasets to create songplays table artist_id\n",
    "songplays_table = df.join(song_df,(df[\"song\"] == song_df[\"title\"]) & ( df[\"artist\"] == song_df[\"artist_name\"]),\"left\").dropDuplicates()\n",
    "\n",
    "songplays_table = songplays_table.select(\"start_time\", df[\"userId\"].alias(\"user_id\"), \"level\", \"song_id\",\\\n",
    "                                         \"artist_id\", df[\"sessionId\"].alias(\"session_id\"), \"location\",\\\n",
    "                                         month(\"start_time\").alias(\"month\"), year(\"start_time\").alias(\"year\"), \\\n",
    "                                         df[\"userAgent\"].alias(\"user_agent\")).withColumn(\"songplay_id\", monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "songplays_table.write.option(\"header\",True) \\\n",
    "    .partitionBy(\"year\",\"month\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .parquet(output_data + \"songs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ee = spark.read.parquet(output_data + \"songs\")\n",
    "ee.count()\n",
    "# ee.limit(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+--------------------+--------+---------+\n",
      "|         artist_id|                name|            location|latitude|longitude|\n",
      "+------------------+--------------------+--------------------+--------+---------+\n",
      "|ARDR4AC1187FB371A1|Montserrat Caball...|                    |    null|     null|\n",
      "|ARMAC4T1187FB3FA4C|The Dillinger Esc...|   Morris Plains, NJ|40.82624|-74.47995|\n",
      "|ARNF6401187FB57032|   Sophie B. Hawkins|New York, NY [Man...|40.79086|-73.96644|\n",
      "|AROUOZZ1187B9ABE51|         Willie Bobo|New York, NY [Spa...|40.79195|-73.94512|\n",
      "|ARI2JSK1187FB496EF|Nick Ingman;Gavyn...|     London, England|51.50632| -0.12714|\n",
      "|AREBBGV1187FB523D2|Mike Jones (Featu...|         Houston, TX|    null|     null|\n",
      "|ARD842G1187B997376|          Blue Rodeo|Toronto, Ontario,...|43.64856|-79.38533|\n",
      "|AR9AWNF1187B9AB0B4|Kenny G featuring...|Seattle, Washingt...|    null|     null|\n",
      "|AR10USD1187B99F3F1|Tweeterfriendly M...|Burlington, Ontar...|    null|     null|\n",
      "|ARIG6O41187B988BDD|     Richard Souther|       United States|37.16793|-95.84502|\n",
      "+------------------+--------------------+--------------------+--------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ee = spark.read.parquet(output_data + \"artists\")\n",
    "ee.count()\n",
    "ee.limit(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+---+----+-------+----+-----+\n",
      "|         start_time|hour|day|week|weekday|year|month|\n",
      "+-------------------+----+---+----+-------+----+-----+\n",
      "|2018-11-15 09:54:18|   9| 15|  46|      4|2018|   11|\n",
      "|2018-11-15 14:57:44|  14| 15|  46|      4|2018|   11|\n",
      "|2018-11-15 15:21:50|  15| 15|  46|      4|2018|   11|\n",
      "|2018-11-15 16:42:54|  16| 15|  46|      4|2018|   11|\n",
      "|2018-11-21 05:07:40|   5| 21|  47|      3|2018|   11|\n",
      "|2018-11-21 05:14:42|   5| 21|  47|      3|2018|   11|\n",
      "|2018-11-21 09:17:45|   9| 21|  47|      3|2018|   11|\n",
      "|2018-11-21 13:23:15|  13| 21|  47|      3|2018|   11|\n",
      "|2018-11-21 15:30:00|  15| 21|  47|      3|2018|   11|\n",
      "|2018-11-14 06:03:05|   6| 14|  46|      3|2018|   11|\n",
      "+-------------------+----+---+----+-------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ee = spark.read.parquet(output_data + \"time\")\n",
    "# ee.count()\n",
    "ee.limit(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+---------+------+-----+\n",
      "|user_id|first_name|last_name|gender|level|\n",
      "+-------+----------+---------+------+-----+\n",
      "|     88|  Mohammad|Rodriguez|     M| paid|\n",
      "|     75|    Joseph|Gutierrez|     M| free|\n",
      "|     53|   Celeste| Williams|     F| free|\n",
      "|     60|     Devin|   Larson|     M| free|\n",
      "|     68|    Jordan|Rodriguez|     F| free|\n",
      "|     90|    Andrea|   Butler|     F| free|\n",
      "|     14|  Theodore|   Harris|     M| free|\n",
      "|      2|   Jizelle| Benjamin|     F| free|\n",
      "|     77| Magdalene|   Herman|     F| free|\n",
      "|     89|   Kynnedi|  Sanchez|     F| free|\n",
      "+-------+----------+---------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ee = spark.read.parquet(output_data + \"users\")\n",
    "# ee.count()\n",
    "ee.limit(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+-----+-------+---------+----------+--------------------+--------------------+------------+----+-----+\n",
      "|         start_time|user_id|level|song_id|artist_id|session_id|            location|          user_agent| songplay_id|year|month|\n",
      "+-------------------+-------+-----+-------+---------+----------+--------------------+--------------------+------------+----+-----+\n",
      "|2018-11-15 16:28:02|     97| paid|   null|     null|       605|Lansing-East Lans...|\"Mozilla/5.0 (X11...|257698037760|2018|   11|\n",
      "|2018-11-15 17:56:18|     97| paid|   null|     null|       605|Lansing-East Lans...|\"Mozilla/5.0 (X11...|257698037761|2018|   11|\n",
      "|2018-11-15 22:23:48|     49| paid|   null|     null|       630|San Francisco-Oak...|Mozilla/5.0 (Wind...|257698037762|2018|   11|\n",
      "|2018-11-21 11:40:46|     15| paid|   null|     null|       764|Chicago-Napervill...|\"Mozilla/5.0 (X11...|257698037763|2018|   11|\n",
      "|2018-11-21 15:33:44|     58| paid|   null|     null|       768|Augusta-Richmond ...|\"Mozilla/5.0 (Win...|257698037764|2018|   11|\n",
      "|2018-11-21 20:52:36|     91| free|   null|     null|       645|Dallas-Fort Worth...|Mozilla/5.0 (comp...|257698037765|2018|   11|\n",
      "|2018-11-14 00:26:55|     95| paid|   null|     null|       411|   Winston-Salem, NC|\"Mozilla/5.0 (iPh...|257698037766|2018|   11|\n",
      "|2018-11-14 09:26:16|     58| paid|   null|     null|       522|Augusta-Richmond ...|\"Mozilla/5.0 (Win...|257698037767|2018|   11|\n",
      "|2018-11-14 16:51:11|     80| paid|   null|     null|       574|Portland-South Po...|\"Mozilla/5.0 (Mac...|257698037768|2018|   11|\n",
      "|2018-11-28 12:15:49|     82| paid|   null|     null|       140|Atlanta-Sandy Spr...|\"Mozilla/5.0 (Mac...|257698037769|2018|   11|\n",
      "+-------------------+-------+-----+-------+---------+----------+--------------------+--------------------+------------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ee = spark.read.parquet(output_data + \"songplays\")\n",
    "# ee.count()\n",
    "ee.limit(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# get filepath to log data file\n",
    "log_data = \"log-data/*.json\"\n",
    "song_data = input_data + \"song-data/song-data/*/*/*/*.json\" \n",
    "# read log data file\n",
    "df = spark.read.json(log_data)\n",
    "\n",
    "# filter by actions for song plays\n",
    "df = df.filter(df.page == 'NextSong')\n",
    "\n",
    "# extract columns for users table    \n",
    "users_table = df.select(df[\"userId\"].alias(\"user_id\"), \\\n",
    "                        df[\"firstName\"].alias(\"first_name\"), \\\n",
    "                        df[\"lastName\"].alias(\"last_name\"), \\\n",
    "                        \"gender\", \"level\").dropDuplicates()\n",
    "\n",
    "user_window = Window \\\n",
    "    .partitionBy('user_id') \\\n",
    "    .orderBy(desc('ts')) \\\n",
    "\n",
    "users_table = users_table.withColumn(\"row_number\", row_number().over(user_window))\n",
    "\n",
    "users_table = users_table.filter(users_table.row_number == 1).drop(\"row_number\").drop(\"ts\")\n",
    "\n",
    "# write users table to parquet files\n",
    "users_table.write.option(\"header\",True) \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .parquet(output_data + \"users\")\n",
    "\n",
    "# create timestamp column from original timestamp column\n",
    "get_timestamp = udf(lambda ts : int(int(ts)/1000),  IntegerType())\n",
    "df = df.withColumn(\"timestamp\", get_timestamp(\"ts\"))\n",
    "\n",
    "# create datetime column from original timestamp column\n",
    "get_datetime = udf(lambda ts : datetime.fromtimestamp(ts), TimestampType())\n",
    "df = df.withColumn(\"start_time\", get_datetime(\"timestamp\"))\n",
    "\n",
    "# extract columns to create time table\n",
    "time_table = df.select(\"start_time\", hour(\"start_time\"), day(\"start_time\"), week(\"start_time\"),\\\n",
    "                       month(\"start_time\"), year(\"start_time\"), weekday(\"start_time\")).dropDuplicates()\n",
    "\n",
    "# write time table to parquet files partitioned by year and month\n",
    "time_table.write.option(\"header\",True) \\\n",
    "    .partitionBy(\"year\",\"month\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .parquet(output_data + \"time\")\n",
    "\n",
    "# SELECT DISTINCT\n",
    "#     timestamp 'epoch' + se.ts * interval '0.001 second',\n",
    "#     se.userId,\n",
    "#     se.level,\n",
    "#     ss.song_id,\n",
    "#     ss.artist_id,\n",
    "#     se.sessionId,\n",
    "#     se.location,\n",
    "#     se.userAgent\n",
    "# FROM staging_events se\n",
    "# LEFT JOIN staging_songs ss\n",
    "# ON ss.title = se.song AND ss.artist_name = se.artist\n",
    "# WHERE se.page = 'NextSong'\n",
    "# ;\n",
    "# songplay_id, start_time, user_id, level, song_id, artist_id, session_id, location, user_agent\n",
    "\n",
    "# SELECT song_id, artists.artist_id\n",
    "# FROM songs JOIN artists\n",
    "# ON songs.artist_id = artists.artist_id\n",
    "# WHERE title = %s AND name = %s AND duration = %s\n",
    "# ;\n",
    "# read in song data to use for songplays table\n",
    "song_df = spark.read.json(song_data)\n",
    "\n",
    "# extract columns from joined song and log datasets to create songplays table artist_id\n",
    "songplays_table = df.join(song_df,(df[\"song\"] == artists_table[\"title\"]) & ( df[\"name\"] == songs_table[\"artist\"]),\"left\").dropDuplicates\n",
    "songplays_table = songplays_table.select(\"start_time\", col(\"userId\") as \"user_id\", \"level\", \"song_id\",\\\n",
    "                                         \"artist_id\", col(\"sessionId\") as \"session_id\", \"location\",\\\n",
    "                                         month(\"start_time\"), year(\"start_time\") \\\n",
    "                                         col(\"userAgent\") as \"user_agent\").withColumn(\"songplay_id\", monotonically_increasing_id())\n",
    "\n",
    "# write songplays table to parquet files partitioned by year and month\n",
    "songplays_table.write.option(\"header\",True) \\\n",
    "    .partitionBy(\"year\",\"month\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .parquet(output_data + \"songs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
